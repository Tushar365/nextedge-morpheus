{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eece2d3e-37c0-447d-98af-18c34b0f4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87c21b-93dd-470c-ade2-b7f964b3c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# Load the model without custom quantization config\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 2048\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                          max_seq_length=max_seq_length,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9e92d-48e9-4fad-bb0d-28e66757f0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96132a2-a5e3-411a-9b09-59aade60886a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7669898-fa11-4d1c-8233-ac92b6571a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/3wckqbfj6b32qldxftd02c300000gp/T/ipykernel_29652/2514120329.py:27: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\n"
     ]
    }
   ],
   "source": [
    "filename = \"synData.csv\"\n",
    "\n",
    "df = pd.read_csv(filename, \n",
    "                 names=[\"sentiment\", \"text\"],\n",
    "                 encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "X_train = list()\n",
    "X_test = list()\n",
    "sentiments=df.sentiment.unique()\n",
    "sentiment_string=\"\\n \".join(sentiments)\n",
    "for sentiment in sentiments:\n",
    "    train, test  = train_test_split(df[df.sentiment==sentiment], \n",
    "                                    train_size=0.8,\n",
    "                                    test_size=0.2, \n",
    "                                    stratify=df[df.sentiment==sentiment].sentiment,\n",
    "                                    random_state=42)\n",
    "    X_train.append(train)\n",
    "    X_test.append(test)\n",
    "\n",
    "X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "X_test = pd.concat(X_test)\n",
    "\n",
    "eval_idx = [idx for idx in df.index if idx not in list(train.index) + list(test.index)]\n",
    "X_eval = df[df.index.isin(eval_idx)]\n",
    "X_eval = (X_eval\n",
    "          .groupby('sentiment', group_keys=False)\n",
    "          .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"The sentiment of the following phrase: '{data_point[\"text\"]}' is \\n{sentiment_string}\\nCannot be determined\n",
    "            \\n\\nSolution: The correct option is {data_point[\"sentiment\"]}\"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"The sentiment of the following phrase: '{data_point[\"text\"]}' is \\n{sentiment_string}\\nCannot be determined\n",
    "            \\n\\nSolution: The correct option is\"\"\".strip()\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"text\"])\n",
    "\n",
    "y_true = X_test.sentiment\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f955082c-5b4a-4648-a5eb-da3357fcf479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the following phrase: '\"MAKE MONEY FAST!!! I just made $10,000 in one week using this one simple trick! Check out the link in my profile to learn how you can do it too!!\"' is \n",
      "positive\n",
      " spam\n",
      " neutral\n",
      " misleading\n",
      "Cannot be determined\n",
      "            \n",
      "\n",
      "Solution: The correct option is spam\n"
     ]
    }
   ],
   "source": [
    "for index,row in X_train.iterrows():\n",
    "    print(row[\"text\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e041ff7e-eae7-4aea-b2ea-ba9bcd8cf24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'misleading': 0, 'neutral': 1, 'positive': 2, 'spam': 3}\n"
     ]
    }
   ],
   "source": [
    "sentiments\n",
    "sorted_sentiments = sorted(sentiments)\n",
    "\n",
    "mapping = {sentiment: index for index, sentiment in enumerate(sorted_sentiments)}\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe63d01-7503-41af-b436-72e260919e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25dd8169-c0ef-4d52-bedc-12fc4048024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred,sentiments):\n",
    "    sorted_sentiments = sorted(sentiments)\n",
    "\n",
    "    labels = sorted_sentiments\n",
    "    mapping = {sentiment: index for index, sentiment in enumerate(sorted_sentiments)}\n",
    "\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=list(mapping.values()))\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be8cc2d6-f782-4c6f-853d-d471a8c3bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer, sentiments):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer,\n",
    "                        max_new_tokens = 3, \n",
    "                        temperature = 0.0,\n",
    "                       )\n",
    "        result = pipe(prompt, pad_token_id=pipe.tokenizer.eos_token_id)\n",
    "        answer = result[0]['generated_text'].split(\"The correct option is\")[-1].lower()\n",
    "        selection=False\n",
    "        for sentiment in sentiments:\n",
    "            if sentiment in answer:\n",
    "                y_pred.append(sentiment)\n",
    "                selection=True\n",
    "                break\n",
    "        # if \"positive\" in answer:\n",
    "        #     y_pred.append(\"positive\")\n",
    "        # elif \"negative\" in answer:\n",
    "        #     y_pred.append(\"negative\")\n",
    "        # elif \"neutral\" in answer:\n",
    "        #     y_pred.append(\"neutral\")\n",
    "        if not selection:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "052bc094-41cd-478e-b742-bbaadb6096a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/80 [00:00<?, ?it/s]/Users/dr.ashhadulislam/miniconda3/envs/python310/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n",
      "100%|███████████████████████████████████████████| 80/80 [29:51<00:00, 22.40s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd46541-e8a8-46c3-86c6-2539d5a8957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838\n",
      "Accuracy for label 0: 0.950\n",
      "Accuracy for label 1: 1.000\n",
      "Accuracy for label 2: 1.000\n",
      "Accuracy for label 3: 0.400\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.95      0.76        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "           2       0.95      1.00      0.98        20\n",
      "           3       1.00      0.40      0.57        20\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.88      0.84      0.82        80\n",
      "weighted avg       0.88      0.84      0.82        80\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  1  0  0]\n",
      " [ 0 20  0  0]\n",
      " [ 0  0 20  0]\n",
      " [11  0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e728f7-e171-4ddc-b97b-2c14376e71e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310k",
   "language": "python",
   "name": "python310k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
